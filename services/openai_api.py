"""A module provides a function to complete a prompt with OpenAI's model."""
import os
import random as rand
import logging
from typing import Iterable

from openai import AsyncOpenAI
from openai.types.chat import ChatCompletionMessageParam

from config import load_config


config = load_config()
client = AsyncOpenAI(api_key=config.openai.token)
logger: logging.Logger = logging.getLogger(__name__)


MESSAGES: dict[str, list[str]] = {
    "nobother": [
        "Today, I'm not in the mood for chatting. Please, don't bother me!",
        "Today, I don't feel like sharing anything. Leave me be!",
        "Today, nothing pleases me. I'm not listening to anyone!",
        "Speed, speed - that's my philosophy! No lessons, no listening!",
        "I'm occupied with my thoughts! Nobody should disturb me!",
        "I am free! When I don't want to respond, I won't!",
    ],
    "noinput": [
        "You need to say something, or we can't continue our conversation.",
        "You need to input something, otherwise, there can be no dialogue.",
        "You need to say something, or the chat can't be given attention.",
        "You need to say something to keep the conversation going.",
        "You have to say at least something.",
    ],
}


def get_message(messages_key: str) -> str:
    """Returns a random message from the `MESSAGES` dictionary.

    Args:
        messages_key: The key of the MESSAGES dictionary (gets a messages
            list).

    Returns:
        str: A random message from the MESSAGES dictionary corresponding to
             the given key. If a key or messages don't exists, returns "".
    """
    messages = MESSAGES.get(messages_key, [""])
    message_index = rand.randint(0, len(messages) - 1)
    return messages[message_index]


async def complete(
    messages: Iterable[ChatCompletionMessageParam],
    model: str = "gpt-3.5-turbo",
    frequency_penalty: float | None = None,
    max_tokens: int | None = None,
    presence_penalty: float | None = None,
    stop: str | None = None,
    temperature: str | None = None,
) -> str:
    """Completes the given prompt using OpenAI's language model.

    Args:
        messages: A list of messages comprising the conversation so far.
        model: The name of the model to use for generating the completion.
        frequency_penalty: Number between -2.0 and 2.0. Positive values
            penalize new tokens based on their existing frequency in the text
            so far, decreasing the model's likelihood to repeat the same
            line verbatim.
        max_tokens: The maximum number of tokens to generate in the completion.
        presence_penalty: Number between -2.0 and 2.0. Positive values
            penalize new tokens based on whether they appear in the text so
            far, increasing the model's likelihood to talk about new topics.
        stop: Sequence where the API will stop generating further tokens
            (up to 4 sequences where the API will stop).
        temperature: Controls the randomness of the generated completions
            (between 0 and 2).

    Returns:
        str: The completed text generated by the model.
    """
    try:
        completion = await client.chat.completions.create(
            messages=messages,
            model=model,
            frequency_penalty=frequency_penalty,
            max_tokens=max_tokens,
            presence_penalty=presence_penalty,
            stop=stop,
            temperature=temperature,
        )
    except Exception as e:
        logger.exception(
            "Error while completion: %s. Messages: %s", e, messages
        )
        if config.tg_bot.debug_mode:
            return str(f"Error while completion: {e}")
        else:
            return get_message("on_error")
    message = completion.choices[0].message.content or ""
    return message.strip()


async def audio_to_text(file_path: str, delete_file: bool = True) -> str:
    """Gets audio file path and returns transcribed text.

    Args:
        file_path: The audio file path to transcribe, in one of these formats:
            flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.
        delete_file: Delete audio file after transcribition. Default: True.

    Returns:
        The transcription text of the audio file.
    """
    with open(file_path, "rb") as audio_file:
        transcript = await client.audio.transcriptions.create(
            model="whisper-1", file=audio_file
        )

    if delete_file:
        os.remove(file_path)

    return transcript.text
