"""A module provides a function to complete a prompt with OpenAI's model."""
import logging
import random as rand

from openai import AsyncOpenAI

from config import load_config


config = load_config()
client = AsyncOpenAI(api_key=config.openai.token)
logger: logging.Logger = logging.getLogger(__name__)


MESSAGES = {
    "on_error": [
        "Сегодня я не в настроении болтать. Пожалуйста, не раздражайте меня!",
        "Сегодня я не хочу ничего рассказывать. Не трогайте меня!",
        "Сегодня я ничему не рад. Никого не слушаю!",
        "Скорость, скорость - это моя философия! Никому ничему!",
        "Я - занят своими думами! Нельзя, чтобы кто-нибудь мешал мне!",
        "Я - свободный! Когда не хочу отвечать - не отвечаю!",
    ],
    "noinput": [
        "Ты должен что-то сказать, иначе мы не сможем продолжить разговор.",
        "Ты должен что-то ввести, иначе разговор не случится.",
        "Ты должен что-то сказать, иначе разговору нельзя будет уделить внимания.",
        "Ты должен что-то сказать, чтобы развивался разговор.",
        "Ты должен хоть что-нибудь сказать.",
    ],
}


def get_message(messages_key: str) -> str:
    """Returns a random message from the `MESSAGES` dictionary.

    Args:
        messages_key: The key of the MESSAGES dictionary (gets a messages
            list).

    Returns:
        str: A random message from the MESSAGES dictionary corresponding to
             the given key.

    Raises:
        KeyError: If the given key is not present in the MESSAGES dictionary.
    """
    msg_index = rand.randint(0, len(MESSAGES[messages_key]) - 1)
    return MESSAGES[messages_key][msg_index]


async def complete(
    messages: dict[str, str],
    model: str,
    frequency_penalty: float,
    max_tokens: int,
    presence_penalty: float,
    stop: str,
    temperature: str,
) -> str:
    """Completes the given prompt using OpenAI's language model.

    Args:
        messages: A list of messages comprising the conversation so far.
        model: The name of the model to use for generating the completion.
        frequency_penalty: Number between -2.0 and 2.0. Positive values
            penalize new tokens based on their existing frequency in the text
            so far, decreasing the model's likelihood to repeat the same
            line verbatim.
        max_tokens: The maximum number of tokens to generate in the completion.
        presence_penalty: Number between -2.0 and 2.0. Positive values
            penalize new tokens based on whether they appear in the text so
            far, increasing the model's likelihood to talk about new topics.
        stop: Sequence where the API will stop generating further tokens
            (up to 4 sequences where the API will stop).
        temperature: Controls the randomness of the generated completions
            (between 0 and 2).

    Returns:
        str: The completed text generated by the model.
    """
    try:
        completion = await client.chat.completions.create(
            messages=messages,
            model=model,
            frequency_penalty=frequency_penalty,
            max_tokens=max_tokens,
            presence_penalty=presence_penalty,
            stop=stop,
            temperature=temperature,
        )
    except Exception as e:
        logger.exception(
            "Error while completion: %s. Messages: %s", e, messages
        )
        if config.tg_bot.debug_mode:
            return str(f"Error while completion: {e}")
        else:
            return get_message("on_error")
    message = completion.choices[0].message.content or ""
    return message.strip()


async def audio_to_text(file_path: str) -> str:
    """Gets audio file path and returns transcribed text.

    Args:
        file_path: The audio file path to transcribe, in one of these formats:
            flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.

    Returns:
        The transcription text of the audio file.
    """
    try:
        with open(file_path, "rb") as audio_file:
            transcript = await client.audio.transcriptions.create(
                model="whisper-1", file=audio_file
            )
            return transcript["text"]
    except Exception as e:
        if config.tg_bot.debug_mode:
            return str(f"Error while transcripting: {e}")
        else:
            raise
